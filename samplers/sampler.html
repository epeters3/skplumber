<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>skplumber.samplers.sampler API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>skplumber.samplers.sampler</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from abc import ABC, abstractmethod
import typing as t
from typing import NamedTuple
from time import time

import pandas as pd

from skplumber.primitives.primitive import Primitive
from skplumber.pipeline import Pipeline
from skplumber.consts import ProblemType
from skplumber.metrics import Metric
from skplumber.utils import (
    logger,
    conditional_timeout,
    EvaluationTimeoutError,
    PipelineRunError,
)


class SamplerState(NamedTuple):
    score: float
    pipeline: Pipeline
    train_time: float
    n_iters: int


class PipelineSampler(ABC):
    def run(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        *,
        models: t.List[t.Type[Primitive]],
        transformers: t.List[t.Type[Primitive]],
        problem_type: ProblemType,
        metric: Metric,
        evaluator: t.Callable,
        pipeline_timeout: t.Optional[int],
        num_samples: t.Optional[int] = None,
        callback: t.Union[None, t.Callable, t.List[t.Callable]] = None,
        exit_on_pipeline_error: bool = True,
    ) -&gt; t.Tuple[Pipeline, float, int]:
        &#34;&#34;&#34;Samples `num_samples` pipelines, returning the best one found along the way.
        
        Returns
        -------
        best_pipeline : Pipeline
            The fitted best pipeline trained on the problem.
        best_score : float
            The score of the best pipeline that was trained.
        n_iters : int
            The total number of iterations the sampler completed.
        &#34;&#34;&#34;

        # Validate inputs

        if num_samples is None and callback is None:
            raise ValueError(
                &#34;either num_samples or callback must be&#34;
                &#34; passed so the sampler knows when to stop&#34;
            )

        if num_samples is not None and num_samples &lt; 1:
            raise ValueError(f&#34;num_samples must be &gt;= 1, got {num_samples}&#34;)

        if callback is None:
            callbacks: t.List[t.Callable] = []
        elif callable(callback):
            callbacks = [callback]
        elif isinstance(callback, list):
            callbacks = callback
        else:
            raise ValueError(f&#34;unsupported type &#39;{type(callback)}&#39; for callback arg&#34;)

        # Initialize

        should_timeout = pipeline_timeout is not None
        best_score = metric.worst_value
        best_pipeline = None

        # Conduct the sampling

        i = 0
        while True:
            i += 1
            logger.info(
                f&#34;sampling pipeline {i}&#34;
                f&#34;{&#39;/&#39; + str(num_samples) if num_samples else &#39;&#39;}&#34;
            )
            pipeline = self.sample_pipeline(problem_type, models, transformers)

            try:

                with conditional_timeout(pipeline_timeout, should_timeout):

                    # Train the pipeline and check its performance.

                    start_time = time()
                    test_score = evaluator(pipeline, X, y, metric)
                    logger.info(f&#34;achieved test score: {test_score}&#34;)

                    if (
                        metric.is_better_than(test_score, best_score)
                        or best_pipeline is None
                    ):
                        best_score = test_score
                        best_pipeline = pipeline

                    # Check to see if its time to stop sampling.

                    if callback is not None:
                        # We stop if any callback returns True.
                        train_time = time() - start_time
                        exit_early = any(
                            cb(SamplerState(test_score, pipeline, train_time, i))
                            for cb in callbacks
                        )
                        if exit_early:
                            break

                    if best_score == metric.best_value:
                        logger.info(
                            f&#34;found best possible score {metric.best_value} early, &#34;
                            &#34;stopping the search&#34;
                        )
                        break

                    if num_samples and i &gt;= num_samples:
                        break

            except EvaluationTimeoutError:

                logger.info(&#34;pipeline took too long to evaluate, skipping&#34;)
                logger.debug(pipeline)

            except PipelineRunError as e:

                logger.exception(e)
                if exit_on_pipeline_error:
                    raise e

        return best_pipeline, best_score, i

    @abstractmethod
    def sample_pipeline(
        self,
        problem_type: ProblemType,
        models: t.List[t.Type[Primitive]],
        transformers: t.List[t.Type[Primitive]],
    ) -&gt; Pipeline:
        pass</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="skplumber.samplers.sampler.PipelineSampler"><code class="flex name class">
<span>class <span class="ident">PipelineSampler</span></span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PipelineSampler(ABC):
    def run(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        *,
        models: t.List[t.Type[Primitive]],
        transformers: t.List[t.Type[Primitive]],
        problem_type: ProblemType,
        metric: Metric,
        evaluator: t.Callable,
        pipeline_timeout: t.Optional[int],
        num_samples: t.Optional[int] = None,
        callback: t.Union[None, t.Callable, t.List[t.Callable]] = None,
        exit_on_pipeline_error: bool = True,
    ) -&gt; t.Tuple[Pipeline, float, int]:
        &#34;&#34;&#34;Samples `num_samples` pipelines, returning the best one found along the way.
        
        Returns
        -------
        best_pipeline : Pipeline
            The fitted best pipeline trained on the problem.
        best_score : float
            The score of the best pipeline that was trained.
        n_iters : int
            The total number of iterations the sampler completed.
        &#34;&#34;&#34;

        # Validate inputs

        if num_samples is None and callback is None:
            raise ValueError(
                &#34;either num_samples or callback must be&#34;
                &#34; passed so the sampler knows when to stop&#34;
            )

        if num_samples is not None and num_samples &lt; 1:
            raise ValueError(f&#34;num_samples must be &gt;= 1, got {num_samples}&#34;)

        if callback is None:
            callbacks: t.List[t.Callable] = []
        elif callable(callback):
            callbacks = [callback]
        elif isinstance(callback, list):
            callbacks = callback
        else:
            raise ValueError(f&#34;unsupported type &#39;{type(callback)}&#39; for callback arg&#34;)

        # Initialize

        should_timeout = pipeline_timeout is not None
        best_score = metric.worst_value
        best_pipeline = None

        # Conduct the sampling

        i = 0
        while True:
            i += 1
            logger.info(
                f&#34;sampling pipeline {i}&#34;
                f&#34;{&#39;/&#39; + str(num_samples) if num_samples else &#39;&#39;}&#34;
            )
            pipeline = self.sample_pipeline(problem_type, models, transformers)

            try:

                with conditional_timeout(pipeline_timeout, should_timeout):

                    # Train the pipeline and check its performance.

                    start_time = time()
                    test_score = evaluator(pipeline, X, y, metric)
                    logger.info(f&#34;achieved test score: {test_score}&#34;)

                    if (
                        metric.is_better_than(test_score, best_score)
                        or best_pipeline is None
                    ):
                        best_score = test_score
                        best_pipeline = pipeline

                    # Check to see if its time to stop sampling.

                    if callback is not None:
                        # We stop if any callback returns True.
                        train_time = time() - start_time
                        exit_early = any(
                            cb(SamplerState(test_score, pipeline, train_time, i))
                            for cb in callbacks
                        )
                        if exit_early:
                            break

                    if best_score == metric.best_value:
                        logger.info(
                            f&#34;found best possible score {metric.best_value} early, &#34;
                            &#34;stopping the search&#34;
                        )
                        break

                    if num_samples and i &gt;= num_samples:
                        break

            except EvaluationTimeoutError:

                logger.info(&#34;pipeline took too long to evaluate, skipping&#34;)
                logger.debug(pipeline)

            except PipelineRunError as e:

                logger.exception(e)
                if exit_on_pipeline_error:
                    raise e

        return best_pipeline, best_score, i

    @abstractmethod
    def sample_pipeline(
        self,
        problem_type: ProblemType,
        models: t.List[t.Type[Primitive]],
        transformers: t.List[t.Type[Primitive]],
    ) -&gt; Pipeline:
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="skplumber.samplers.onestack.OneStackPipelineSampler" href="onestack.html#skplumber.samplers.onestack.OneStackPipelineSampler">OneStackPipelineSampler</a></li>
<li><a title="skplumber.samplers.straight.StraightPipelineSampler" href="straight.html#skplumber.samplers.straight.StraightPipelineSampler">StraightPipelineSampler</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="skplumber.samplers.sampler.PipelineSampler.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, X: pandas.core.frame.DataFrame, y: pandas.core.series.Series, *, models: List[Type[<a title="skplumber.primitives.primitive.Primitive" href="../primitives/primitive.html#skplumber.primitives.primitive.Primitive">Primitive</a>]], transformers: List[Type[<a title="skplumber.primitives.primitive.Primitive" href="../primitives/primitive.html#skplumber.primitives.primitive.Primitive">Primitive</a>]], problem_type: <a title="skplumber.consts.ProblemType" href="../consts.html#skplumber.consts.ProblemType">ProblemType</a>, metric: <a title="skplumber.metrics.Metric" href="../metrics.html#skplumber.metrics.Metric">Metric</a>, evaluator: Callable, pipeline_timeout: Union[int, NoneType], num_samples: Union[int, NoneType] = None, callback: Union[NoneType, Callable, List[Callable]] = None, exit_on_pipeline_error: bool = True) -> Tuple[<a title="skplumber.pipeline.Pipeline" href="../pipeline.html#skplumber.pipeline.Pipeline">Pipeline</a>, float, int]</span>
</code></dt>
<dd>
<div class="desc"><p>Samples <code>num_samples</code> pipelines, returning the best one found along the way.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>best_pipeline</code></strong> :&ensp;<code>Pipeline</code></dt>
<dd>The fitted best pipeline trained on the problem.</dd>
<dt><strong><code>best_score</code></strong> :&ensp;<code>float</code></dt>
<dd>The score of the best pipeline that was trained.</dd>
<dt><strong><code>n_iters</code></strong> :&ensp;<code>int</code></dt>
<dd>The total number of iterations the sampler completed.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(
    self,
    X: pd.DataFrame,
    y: pd.Series,
    *,
    models: t.List[t.Type[Primitive]],
    transformers: t.List[t.Type[Primitive]],
    problem_type: ProblemType,
    metric: Metric,
    evaluator: t.Callable,
    pipeline_timeout: t.Optional[int],
    num_samples: t.Optional[int] = None,
    callback: t.Union[None, t.Callable, t.List[t.Callable]] = None,
    exit_on_pipeline_error: bool = True,
) -&gt; t.Tuple[Pipeline, float, int]:
    &#34;&#34;&#34;Samples `num_samples` pipelines, returning the best one found along the way.
    
    Returns
    -------
    best_pipeline : Pipeline
        The fitted best pipeline trained on the problem.
    best_score : float
        The score of the best pipeline that was trained.
    n_iters : int
        The total number of iterations the sampler completed.
    &#34;&#34;&#34;

    # Validate inputs

    if num_samples is None and callback is None:
        raise ValueError(
            &#34;either num_samples or callback must be&#34;
            &#34; passed so the sampler knows when to stop&#34;
        )

    if num_samples is not None and num_samples &lt; 1:
        raise ValueError(f&#34;num_samples must be &gt;= 1, got {num_samples}&#34;)

    if callback is None:
        callbacks: t.List[t.Callable] = []
    elif callable(callback):
        callbacks = [callback]
    elif isinstance(callback, list):
        callbacks = callback
    else:
        raise ValueError(f&#34;unsupported type &#39;{type(callback)}&#39; for callback arg&#34;)

    # Initialize

    should_timeout = pipeline_timeout is not None
    best_score = metric.worst_value
    best_pipeline = None

    # Conduct the sampling

    i = 0
    while True:
        i += 1
        logger.info(
            f&#34;sampling pipeline {i}&#34;
            f&#34;{&#39;/&#39; + str(num_samples) if num_samples else &#39;&#39;}&#34;
        )
        pipeline = self.sample_pipeline(problem_type, models, transformers)

        try:

            with conditional_timeout(pipeline_timeout, should_timeout):

                # Train the pipeline and check its performance.

                start_time = time()
                test_score = evaluator(pipeline, X, y, metric)
                logger.info(f&#34;achieved test score: {test_score}&#34;)

                if (
                    metric.is_better_than(test_score, best_score)
                    or best_pipeline is None
                ):
                    best_score = test_score
                    best_pipeline = pipeline

                # Check to see if its time to stop sampling.

                if callback is not None:
                    # We stop if any callback returns True.
                    train_time = time() - start_time
                    exit_early = any(
                        cb(SamplerState(test_score, pipeline, train_time, i))
                        for cb in callbacks
                    )
                    if exit_early:
                        break

                if best_score == metric.best_value:
                    logger.info(
                        f&#34;found best possible score {metric.best_value} early, &#34;
                        &#34;stopping the search&#34;
                    )
                    break

                if num_samples and i &gt;= num_samples:
                    break

        except EvaluationTimeoutError:

            logger.info(&#34;pipeline took too long to evaluate, skipping&#34;)
            logger.debug(pipeline)

        except PipelineRunError as e:

            logger.exception(e)
            if exit_on_pipeline_error:
                raise e

    return best_pipeline, best_score, i</code></pre>
</details>
</dd>
<dt id="skplumber.samplers.sampler.PipelineSampler.sample_pipeline"><code class="name flex">
<span>def <span class="ident">sample_pipeline</span></span>(<span>self, problem_type: <a title="skplumber.consts.ProblemType" href="../consts.html#skplumber.consts.ProblemType">ProblemType</a>, models: List[Type[<a title="skplumber.primitives.primitive.Primitive" href="../primitives/primitive.html#skplumber.primitives.primitive.Primitive">Primitive</a>]], transformers: List[Type[<a title="skplumber.primitives.primitive.Primitive" href="../primitives/primitive.html#skplumber.primitives.primitive.Primitive">Primitive</a>]]) -> <a title="skplumber.pipeline.Pipeline" href="../pipeline.html#skplumber.pipeline.Pipeline">Pipeline</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def sample_pipeline(
    self,
    problem_type: ProblemType,
    models: t.List[t.Type[Primitive]],
    transformers: t.List[t.Type[Primitive]],
) -&gt; Pipeline:
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="skplumber.samplers.sampler.SamplerState"><code class="flex name class">
<span>class <span class="ident">SamplerState</span></span>
<span>(</span><span>score: float, pipeline: <a title="skplumber.pipeline.Pipeline" href="../pipeline.html#skplumber.pipeline.Pipeline">Pipeline</a>, train_time: float, n_iters: int)</span>
</code></dt>
<dd>
<div class="desc"><p>SamplerState(score, pipeline, train_time, n_iters)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SamplerState(NamedTuple):
    score: float
    pipeline: Pipeline
    train_time: float
    n_iters: int</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.tuple</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="skplumber.samplers.sampler.SamplerState.n_iters"><code class="name">var <span class="ident">n_iters</span> : int</code></dt>
<dd>
<div class="desc"><p>Alias for field number 3</p></div>
</dd>
<dt id="skplumber.samplers.sampler.SamplerState.pipeline"><code class="name">var <span class="ident">pipeline</span> : <a title="skplumber.pipeline.Pipeline" href="../pipeline.html#skplumber.pipeline.Pipeline">Pipeline</a></code></dt>
<dd>
<div class="desc"><p>Alias for field number 1</p></div>
</dd>
<dt id="skplumber.samplers.sampler.SamplerState.score"><code class="name">var <span class="ident">score</span> : float</code></dt>
<dd>
<div class="desc"><p>Alias for field number 0</p></div>
</dd>
<dt id="skplumber.samplers.sampler.SamplerState.train_time"><code class="name">var <span class="ident">train_time</span> : float</code></dt>
<dd>
<div class="desc"><p>Alias for field number 2</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="skplumber.samplers" href="index.html">skplumber.samplers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="skplumber.samplers.sampler.PipelineSampler" href="#skplumber.samplers.sampler.PipelineSampler">PipelineSampler</a></code></h4>
<ul class="">
<li><code><a title="skplumber.samplers.sampler.PipelineSampler.run" href="#skplumber.samplers.sampler.PipelineSampler.run">run</a></code></li>
<li><code><a title="skplumber.samplers.sampler.PipelineSampler.sample_pipeline" href="#skplumber.samplers.sampler.PipelineSampler.sample_pipeline">sample_pipeline</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="skplumber.samplers.sampler.SamplerState" href="#skplumber.samplers.sampler.SamplerState">SamplerState</a></code></h4>
<ul class="">
<li><code><a title="skplumber.samplers.sampler.SamplerState.n_iters" href="#skplumber.samplers.sampler.SamplerState.n_iters">n_iters</a></code></li>
<li><code><a title="skplumber.samplers.sampler.SamplerState.pipeline" href="#skplumber.samplers.sampler.SamplerState.pipeline">pipeline</a></code></li>
<li><code><a title="skplumber.samplers.sampler.SamplerState.score" href="#skplumber.samplers.sampler.SamplerState.score">score</a></code></li>
<li><code><a title="skplumber.samplers.sampler.SamplerState.train_time" href="#skplumber.samplers.sampler.SamplerState.train_time">train_time</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>